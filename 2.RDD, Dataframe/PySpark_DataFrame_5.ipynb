{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark==3.3.1 py4j==0.10.9.5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_Wyv6ahKs8R",
        "outputId": "7c2359b2-6d54-499b-b08e-6c0f9213b61e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.3.1-py2.py3-none-any.whl size=281845512 sha256=9e8f4c20833098e80654aff6a339464152154519aceb6d8759ec34f3060bdce7\n",
            "  Stored in directory: /root/.cache/pip/wheels/43/dc/11/ec201cd671da62fa9c5cc77078235e40722170ceba231d7598\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.5 pyspark-3.3.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd /usr/local/lib/python3.8/dist-packages/pyspark/jars && wget https://s3.amazonaws.com/redshift-downloads/drivers/jdbc/1.2.20.1043/RedshiftJDBC42-no-awssdk-1.2.20.1043.jar"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fs8ZOFnIIvgX",
        "outputId": "304d4ffc-1632-4dfd-85e5-662b2414db6f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-01-16 23:20:12--  https://s3.amazonaws.com/redshift-downloads/drivers/jdbc/1.2.20.1043/RedshiftJDBC42-no-awssdk-1.2.20.1043.jar\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.97.221, 54.231.197.16, 54.231.233.80, ...\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.97.221|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2413910 (2.3M) [application/java-archive]\n",
            "Saving to: ‘RedshiftJDBC42-no-awssdk-1.2.20.1043.jar’\n",
            "\n",
            "RedshiftJDBC42-no-a 100%[===================>]   2.30M  12.9MB/s    in 0.2s    \n",
            "\n",
            "2023-01-16 23:20:13 (12.9 MB/s) - ‘RedshiftJDBC42-no-awssdk-1.2.20.1043.jar’ saved [2413910/2413910]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession \\\n",
        "    .builder \\\n",
        "    .appName(\"PySpark DataFrame #5\") \\\n",
        "    .getOrCreate()"
      ],
      "metadata": {
        "id": "zS9lNDeRKygm"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_vqm-DsuH_hO"
      },
      "source": [
        "## Redshift와 연결해서 테이블들을 데이터프레임으로 로딩하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEaNuN3xKNXm"
      },
      "source": [
        "df_user_session_channel = spark.read \\\n",
        "    .format(\"jdbc\") \\\n",
        "    .option(\"driver\", \"com.amazon.redshift.jdbc42.Driver\") \\\n",
        "    .option(\"url\", \"jdbc:redshift://learnde.cduaw970ssvt.ap-northeast-2.redshift.amazonaws.com:5439/dev?user=guest&password=Guest1234\") \\\n",
        "    .option(\"dbtable\", \"raw_data.user_session_channel\") \\\n",
        "    .load()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQlBPcO_INv9"
      },
      "source": [
        "df_session_timestamp = spark.read \\\n",
        "    .format(\"jdbc\") \\\n",
        "    .option(\"driver\", \"com.amazon.redshift.jdbc42.Driver\") \\\n",
        "    .option(\"url\", \"jdbc:redshift://learnde.cduaw970ssvt.ap-northeast-2.redshift.amazonaws.com:5439/dev?user=guest&password=Guest1234\") \\\n",
        "    .option(\"dbtable\", \"raw_data.session_timestamp\") \\\n",
        "    .load()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_user_session_channel.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g0XNWXQ22CB4",
        "outputId": "403b9cc5-cedc-4257-81e6-e27c570f91d8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- userid: integer (nullable = true)\n",
            " |-- sessionid: string (nullable = true)\n",
            " |-- channel: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_user_session_channel.rdd.getNumPartitions()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILp2JBiL2TyI",
        "outputId": "245448be-10b7-4ccf-a258-a42f5e592cfe"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_session_timestamp.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28Jb0ZvB2E7f",
        "outputId": "37982bbf-002d-4d7a-d529-24336e78136c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- sessionid: string (nullable = true)\n",
            " |-- ts: timestamp (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_session_timestamp.rdd.getNumPartitions()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xbu2KXxD2Y78",
        "outputId": "f3406d1f-4af6-43f7-8b37-1f6403ad4002"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DataFrame으로 처리하기"
      ],
      "metadata": {
        "id": "I0ejADf9IV7M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "join_expr = df_user_session_channel.sessionid == df_session_timestamp.sessionid\n",
        "session_df = df_user_session_channel.join(df_session_timestamp, join_expr, \"inner\")"
      ],
      "metadata": {
        "id": "X2kYjwWDIZGk"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "session_df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jUOkGRw32kbp",
        "outputId": "338bfc10-7eea-47ac-bd70-9dcce3f7a24d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- userid: integer (nullable = true)\n",
            " |-- sessionid: string (nullable = true)\n",
            " |-- channel: string (nullable = true)\n",
            " |-- sessionid: string (nullable = true)\n",
            " |-- ts: timestamp (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "session_df.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yxpfx65l3R1M",
        "outputId": "38b82977-3b4c-43dc-cf0d-90412e6953d5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+--------------------+--------+--------------------+--------------------+\n",
            "|userid|           sessionid| channel|           sessionid|                  ts|\n",
            "+------+--------------------+--------+--------------------+--------------------+\n",
            "|  1501|0135456d6a3c1051f...|  Google|0135456d6a3c1051f...|2019-09-24 14:49:...|\n",
            "|   876|01a416a7e28d0d229...|Facebook|01a416a7e28d0d229...|2019-05-26 14:23:...|\n",
            "|  2133|02ea66ee24d57e285...| Organic|02ea66ee24d57e285...| 2019-10-28 22:50:40|\n",
            "|  1961|0302915889fa38fe5...| Youtube|0302915889fa38fe5...| 2019-11-29 15:16:49|\n",
            "|   599|03ce0331cbd983f16...| Organic|03ce0331cbd983f16...|2019-07-18 13:49:...|\n",
            "+------+--------------------+--------+--------------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "session_df = df_user_session_channel.join(df_session_timestamp, join_expr, \"inner\").select(\n",
        "    \"userid\", \"sessionid\", \"channel\", \"ts\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "id": "eDjLW6VE3II1",
        "outputId": "b99cbde2-d17b-4dc5-ef57-a82506d8a6bf"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AnalysisException",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-70558d8e0e24>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m session_df = df_user_session_channel.join(df_session_timestamp, join_expr, \"inner\").select(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;34m\"userid\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"sessionid\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"channel\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ts\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, *cols)\u001b[0m\n\u001b[1;32m   2021\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Alice'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Bob'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2022\u001b[0m         \"\"\"\n\u001b[0;32m-> 2023\u001b[0;31m         \u001b[0mjdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jcols\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2024\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparkSession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1321\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1322\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    194\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAnalysisException\u001b[0m: Reference 'sessionid' is ambiguous, could be: sessionid, sessionid."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "session_df = df_user_session_channel.join(df_session_timestamp, join_expr, \"inner\").select(\n",
        "    \"userid\", df_user_session_channel.sessionid, \"channel\", \"ts\"\n",
        ")"
      ],
      "metadata": {
        "id": "quHfBJCd3Y6v"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "channel_count_df = session_df.groupby(\"channel\").count().orderBy(\"count\", ascending=False)"
      ],
      "metadata": {
        "id": "JXkFN_OO3iu9"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "channel_count_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EzMiG4493trM",
        "outputId": "91f23d89-c69b-4170-9e7c-30e47de668fb"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-----+\n",
            "|  channel|count|\n",
            "+---------+-----+\n",
            "|  Youtube|17091|\n",
            "|   Google|16982|\n",
            "|    Naver|16921|\n",
            "|  Organic|16904|\n",
            "|Instagram|16831|\n",
            "| Facebook|16791|\n",
            "+---------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import date_format, asc, countDistinct\n",
        "\n",
        "session_df.withColumn('month', date_format('ts', 'yyyy-MM')).groupby('month').\\\n",
        "    agg(countDistinct(\"userid\").alias(\"mau\")).sort(asc('month')).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DnVN-Jv530nA",
        "outputId": "5f672563-a516-4085-bab7-b7eb9e5cb372"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+---+\n",
            "|  month|mau|\n",
            "+-------+---+\n",
            "|2019-05|281|\n",
            "|2019-06|459|\n",
            "|2019-07|623|\n",
            "|2019-08|662|\n",
            "|2019-09|639|\n",
            "|2019-10|763|\n",
            "|2019-11|721|\n",
            "+-------+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Spark SQL로  처리하기"
      ],
      "metadata": {
        "id": "BEuhmxeGIRkI"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cb87SiYQ3lX8"
      },
      "source": [
        "df_user_session_channel.createOrReplaceTempView(\"user_session_channel\")"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFMFrRpP3sP6"
      },
      "source": [
        "df_session_timestamp.createOrReplaceTempView(\"session_timestamp\")"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GdiSxs1030G0"
      },
      "source": [
        "channel_count_df = spark.sql(\"\"\"\n",
        "    SELECT channel, count(distinct userId) uniqueUsers\n",
        "    FROM session_timestamp st\n",
        "    JOIN user_session_channel usc ON st.sessionID = usc.sessionID\n",
        "    GROUP BY 1\n",
        "    ORDER BY 1\n",
        "\"\"\")"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1C5HKcd61_j",
        "outputId": "52cc3ca6-3c0a-4730-e9b4-33e6147b8f18"
      },
      "source": [
        "channel_count_df"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[channel: string, uniqueUsers: bigint]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "whIte26D63hG",
        "outputId": "29669143-c00d-46db-dd5f-2b5e37e5cef3"
      },
      "source": [
        "channel_count_df.show()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-----------+\n",
            "|  channel|uniqueUsers|\n",
            "+---------+-----------+\n",
            "| Facebook|        889|\n",
            "|   Google|        893|\n",
            "|Instagram|        895|\n",
            "|    Naver|        882|\n",
            "|  Organic|        895|\n",
            "|  Youtube|        889|\n",
            "+---------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vE8iL4vy6705"
      },
      "source": [
        "mau_df = spark.sql(\"\"\"\n",
        "SELECT \n",
        "  LEFT(A.ts, 7) AS month,\n",
        "  COUNT(DISTINCT B.userid) AS mau\n",
        "FROM session_timestamp A\n",
        "JOIN user_session_channel B ON A.sessionid = B.sessionid\n",
        "GROUP BY 1      \n",
        "ORDER BY 1 DESC\"\"\")"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QU44opcvDE54",
        "outputId": "c147616f-946f-420b-c38e-c08213c0b19c"
      },
      "source": [
        "mau_df.collect()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(month='2019-11', mau=721),\n",
              " Row(month='2019-10', mau=763),\n",
              " Row(month='2019-09', mau=639),\n",
              " Row(month='2019-08', mau=662),\n",
              " Row(month='2019-07', mau=623),\n",
              " Row(month='2019-06', mau=459),\n",
              " Row(month='2019-05', mau=281)]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    }
  ]
}
