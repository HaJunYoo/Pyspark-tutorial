{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "LoCk7SgRrFuP",
        "QkvG7CGo1BgF",
        "YV16sPAT04lt",
        "cdANBnd70u-E",
        "ziIgaC_cXx8S",
        "1bbYGM8MX3zO",
        "9nO5mhnwPozH",
        "uBXdq3jqPwur"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XIA23YgbXKJd"
      },
      "source": [
        "이를 위해 pyspark과 Py4J 패키지를 설치한다. Py4J 패키지는 파이썬 프로그램이 자바가상머신상의 오브젝트들을 접근할 수 있게 해준다. Local Standalone Spark을 사용한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NbT0rpGfVdiq",
        "outputId": "ffa111f6-3aac-4a8f-a768-1ba3a05d48e5"
      },
      "source": [
        "!pip install pyspark==3.3.1 py4j==0.10.9.5 "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyspark==3.3.1 in /usr/local/lib/python3.8/dist-packages (3.3.1)\n",
            "Requirement already satisfied: py4j==0.10.9.5 in /usr/local/lib/python3.8/dist-packages (0.10.9.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ew_eTGrvXlDw"
      },
      "source": [
        "**Spark Session**을 하나 만든다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vm6tgcPXdnR"
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession \\\n",
        "    .builder \\\n",
        "    .appName(\"Python Spark Unit Test\") \\\n",
        "    .getOrCreate()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://s3-geospatial.s3-us-west-2.amazonaws.com/name_gender.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UKrMnuGVK77P",
        "outputId": "06de4c0d-4a0a-4f02-e3ed-35580210f7c5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-01-24 06:32:50--  https://s3-geospatial.s3-us-west-2.amazonaws.com/name_gender.csv\n",
            "Resolving s3-geospatial.s3-us-west-2.amazonaws.com (s3-geospatial.s3-us-west-2.amazonaws.com)... 52.92.250.34, 52.218.132.73, 52.218.224.105, ...\n",
            "Connecting to s3-geospatial.s3-us-west-2.amazonaws.com (s3-geospatial.s3-us-west-2.amazonaws.com)|52.92.250.34|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 997 [text/csv]\n",
            "Saving to: ‘name_gender.csv.3’\n",
            "\n",
            "name_gender.csv.3   100%[===================>]     997  --.-KB/s    in 0s      \n",
            "\n",
            "2023-01-24 06:32:50 (49.1 MB/s) - ‘name_gender.csv.3’ saved [997/997]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read.option(\"header\", True).csv(\"name_gender.csv\")\n",
        "df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ZhdS0i7LZEc",
        "outputId": "f0f3fda8-4dcf-4cef-f8db-f8aab3ba6422"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- name: string (nullable = true)\n",
            " |-- gender: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vGFDiqDcLeq7",
        "outputId": "ebabb5a2-59dd-46c3-f60e-bfc7fe233d1d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.createOrReplaceTempView(\"namegender\")\n",
        "spark.sql(\"SELECT gender, COUNT(1) count FROM namegender GROUP BY 1\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wmbJXYQ0LlUB",
        "outputId": "913d54cb-4e01-4d3b-d564-056a522899e5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----+\n",
            "|gender|count|\n",
            "+------+-----+\n",
            "|     F|   65|\n",
            "|     M|   28|\n",
            "|Unisex|    7|\n",
            "+------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import pandas_udf\n",
        "from pyspark.sql.types import *\n",
        "import pandas as pd\n",
        "\n",
        "# Define the UDF\n",
        "@pandas_udf(StringType())\n",
        "def upper_udf_f(s: pd.Series) -> pd.Series:\n",
        "    return s.str.upper()\n",
        "\n",
        "upperUDF = spark.udf.register(\"upper_udf\", upper_udf_f)"
      ],
      "metadata": {
        "id": "-Y0CL9EpMO-h"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_gender(spark, file_path):\n",
        "    return spark.read.option(\"header\", True).csv(file_path)\n",
        "\n",
        "def get_gender_count(spark, df, field_to_count):\n",
        "    df.createOrReplaceTempView(\"namegender_test\")\n",
        "    return spark.sql(f\"SELECT {field_to_count}, COUNT(1) count FROM namegender_test GROUP BY 1\")"
      ],
      "metadata": {
        "id": "dRLF06SILaP_"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = load_gender(spark, \"name_gender.csv\")\n",
        "get_gender_count(spark, df, \"gender\").show()\n",
        "df.select(upperUDF(\"name\").alias(\"NAME\")).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_WT4JmtMsn4",
        "outputId": "1be49c10-784d-4e2f-fb62-a2db56ea5474"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----+\n",
            "|gender|count|\n",
            "+------+-----+\n",
            "|     F|   65|\n",
            "|     M|   28|\n",
            "|Unisex|    7|\n",
            "+------+-----+\n",
            "\n",
            "+----------+\n",
            "|      NAME|\n",
            "+----------+\n",
            "|  ADALEIGH|\n",
            "|     AMRYN|\n",
            "|    APURVA|\n",
            "|    ARYION|\n",
            "|    ALIXIA|\n",
            "|ALYSSAROSE|\n",
            "|    ARVELL|\n",
            "|     AIBEL|\n",
            "|   ATIYYAH|\n",
            "|     ADLIE|\n",
            "|    ANYELY|\n",
            "|    AAMONI|\n",
            "|     AHMAN|\n",
            "|    ARLANE|\n",
            "|   ARMONEY|\n",
            "|   ATZHIRY|\n",
            "| ANTONETTE|\n",
            "|   AKEELAH|\n",
            "| ABDIKADIR|\n",
            "|    ARINZE|\n",
            "+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.select(upperUDF(\"name\").alias(\"NAME\")).collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MFg5z8O-Qv54",
        "outputId": "d30f433a-2fc2-4de0-9069-ba1132a1694e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(NAME='ADALEIGH'),\n",
              " Row(NAME='AMRYN'),\n",
              " Row(NAME='APURVA'),\n",
              " Row(NAME='ARYION'),\n",
              " Row(NAME='ALIXIA'),\n",
              " Row(NAME='ALYSSAROSE'),\n",
              " Row(NAME='ARVELL'),\n",
              " Row(NAME='AIBEL'),\n",
              " Row(NAME='ATIYYAH'),\n",
              " Row(NAME='ADLIE'),\n",
              " Row(NAME='ANYELY'),\n",
              " Row(NAME='AAMONI'),\n",
              " Row(NAME='AHMAN'),\n",
              " Row(NAME='ARLANE'),\n",
              " Row(NAME='ARMONEY'),\n",
              " Row(NAME='ATZHIRY'),\n",
              " Row(NAME='ANTONETTE'),\n",
              " Row(NAME='AKEELAH'),\n",
              " Row(NAME='ABDIKADIR'),\n",
              " Row(NAME='ARINZE'),\n",
              " Row(NAME='ARSHAUN'),\n",
              " Row(NAME='ALEXANDRO'),\n",
              " Row(NAME='AYRIAUNA'),\n",
              " Row(NAME='AQIB'),\n",
              " Row(NAME='ALLEYA'),\n",
              " Row(NAME='AAVAH'),\n",
              " Row(NAME='ANESTI'),\n",
              " Row(NAME='ADALAIDE'),\n",
              " Row(NAME='ANALENA'),\n",
              " Row(NAME='ALAEYAH'),\n",
              " Row(NAME='ALBENA'),\n",
              " Row(NAME='AIMI'),\n",
              " Row(NAME='ADWAITH'),\n",
              " Row(NAME='ARKADY'),\n",
              " Row(NAME='ASTYN'),\n",
              " Row(NAME='ADELEE'),\n",
              " Row(NAME='AGATA'),\n",
              " Row(NAME='ALEGNA'),\n",
              " Row(NAME='ALTAN'),\n",
              " Row(NAME='AHNALEIGH'),\n",
              " Row(NAME='ALGIE'),\n",
              " Row(NAME='ASHANTI'),\n",
              " Row(NAME='AISLYN'),\n",
              " Row(NAME='ADALEINE'),\n",
              " Row(NAME='ANTHNOY'),\n",
              " Row(NAME='ALGERNON'),\n",
              " Row(NAME='AERYONA'),\n",
              " Row(NAME='ADRINNE'),\n",
              " Row(NAME='ADDELL'),\n",
              " Row(NAME='AVRIL'),\n",
              " Row(NAME='AHNI'),\n",
              " Row(NAME='AIMON'),\n",
              " Row(NAME='ADOLPHO'),\n",
              " Row(NAME='AHUVA'),\n",
              " Row(NAME='AURIELLE'),\n",
              " Row(NAME='AVEANA'),\n",
              " Row(NAME='ALIYIA'),\n",
              " Row(NAME='ALESANDER'),\n",
              " Row(NAME='ADNREA'),\n",
              " Row(NAME='ANJAE'),\n",
              " Row(NAME='ALVINE'),\n",
              " Row(NAME='ADORAH'),\n",
              " Row(NAME='ADLEMI'),\n",
              " Row(NAME='ALESI'),\n",
              " Row(NAME='ALONTAE'),\n",
              " Row(NAME='ANTONNY'),\n",
              " Row(NAME='ADARAH'),\n",
              " Row(NAME='AYREANNA'),\n",
              " Row(NAME='ANTYON'),\n",
              " Row(NAME='ANDIA'),\n",
              " Row(NAME='ASHLA'),\n",
              " Row(NAME='ASPYN'),\n",
              " Row(NAME='ANTWANETT'),\n",
              " Row(NAME='AUNDREIA'),\n",
              " Row(NAME='AUDELLA'),\n",
              " Row(NAME='AMARI'),\n",
              " Row(NAME='ARSHA'),\n",
              " Row(NAME='ARICELLA'),\n",
              " Row(NAME='ADAN'),\n",
              " Row(NAME='APASRA'),\n",
              " Row(NAME='ALAYSHA'),\n",
              " Row(NAME='ANDERSON'),\n",
              " Row(NAME='AURELIUS'),\n",
              " Row(NAME='AERIAL'),\n",
              " Row(NAME='AVERLEIGH'),\n",
              " Row(NAME='ASLEAN'),\n",
              " Row(NAME='ARNIESHA'),\n",
              " Row(NAME='ASYANA'),\n",
              " Row(NAME='ANNJANE'),\n",
              " Row(NAME='AMABELLA'),\n",
              " Row(NAME='AUSTINJOHN'),\n",
              " Row(NAME='ARLOWEEN'),\n",
              " Row(NAME='ALULA'),\n",
              " Row(NAME='ANEMONE'),\n",
              " Row(NAME='AMORINA'),\n",
              " Row(NAME='ANUREET'),\n",
              " Row(NAME='ARRIC'),\n",
              " Row(NAME='ANTONNE'),\n",
              " Row(NAME='ALYRE'),\n",
              " Row(NAME='ANNAISE')]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 유닛 테스트 코드 붙여보기"
      ],
      "metadata": {
        "id": "kO6tHzLzLR8G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from unittest import TestCase\n",
        "\n",
        "# 일반적으로는 아래 함수가 정의된 모듈을 임포트하고 그걸 테스트\n",
        "#  - upper_udf_f\n",
        "#  - load_gender\n",
        "#  - get_gender_count\n",
        "\n",
        "class UtilsTestCase(TestCase):\n",
        "    spark = None\n",
        "\n",
        "    @classmethod\n",
        "    def setUpClass(cls) -> None:\n",
        "        cls.spark = SparkSession.builder \\\n",
        "            .appName(\"Spark Unit Test\") \\\n",
        "            .getOrCreate()\n",
        "\n",
        "    def test_datafile_loading(self):\n",
        "        sample_df = load_gender(self.spark, \"name_gender.csv\")\n",
        "        result_count = sample_df.count()\n",
        "        self.assertEqual(result_count, 100, \"Record count should be 100\")\n",
        "\n",
        "    def test_gender_count(self):\n",
        "        sample_df = load_gender(self.spark, \"name_gender.csv\")\n",
        "        count_list = get_gender_count(self.spark, sample_df, \"gender\").collect()\n",
        "        count_dict = dict()\n",
        "        for row in count_list:\n",
        "            count_dict[row[\"gender\"]] = row[\"count\"]\n",
        "        self.assertEqual(count_dict[\"F\"], 65, \"Count for F should be 65\")\n",
        "        self.assertEqual(count_dict[\"M\"], 28, \"Count for M should be 28\")\n",
        "        self.assertEqual(count_dict[\"Unisex\"], 7, \"Count for Unisex should be 7\")\n",
        "\n",
        "    def test_upper_udf(self):\n",
        "        test_data = [\n",
        "            { \"name\": \"John Kim\" },\n",
        "            { \"name\": \"Johnny Kim\"},\n",
        "            { \"name\": \"1234\" }\n",
        "        ]\n",
        "        expected_results = [ \"JOHN KIM\", \"JOHNNY KIM\", \"1234\" ]\n",
        "\n",
        "        upperUDF = self.spark.udf.register(\"upper_udf\", upper_udf_f)\n",
        "        test_df = self.spark.createDataFrame(test_data)\n",
        "        names = test_df.select(\"name\", upperUDF(\"name\").alias(\"NAME\")).collect()\n",
        "        results = []\n",
        "        for name in names:\n",
        "            results.append(name[\"NAME\"])\n",
        "        self.assertCountEqual(results, expected_results)\n",
        "\n",
        "    @classmethod\n",
        "    def tearDownClass(cls) -> None:\n",
        "        cls.spark.stop()"
      ],
      "metadata": {
        "id": "LeGWFXXpIpOm"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import unittest\n",
        "\n",
        "unittest.main(argv=[''], verbosity=2, exit=False)"
      ],
      "metadata": {
        "id": "HFE9zkakGA55",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7027f30b-4a05-45c0-8a56-dafd61af7297"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "test_datafile_loading (__main__.UtilsTestCase) ... ok\n",
            "test_gender_count (__main__.UtilsTestCase) ... ok\n",
            "test_upper_udf (__main__.UtilsTestCase) ... ok\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "Ran 3 tests in 4.486s\n",
            "\n",
            "OK\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<unittest.main.TestProgram at 0x7f41a42a5fa0>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    }
  ]
}